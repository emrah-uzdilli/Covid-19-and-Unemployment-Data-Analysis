# Covid-19-and-Unemployment-Data-Analysis

The COVID-19 crisis is one such shock, In 2020, urgent care centers saw visits increase 58% with record-high patient volumes during the second half of the year. First-time visitors accounted for nearly half of the 28 million patients who used urgent care. That spike in activity was driven by high demand for COVID-19 testing. By early 2022, the Centers for Disease Control and Prevention (CDC) had tracked more than 75 million cases of COVID-19 in the U.S., and some models suggest the total number of infections is much higher. The scale of the pandemic has had a significant impact on the health insurance sector. Health insurers are responsible for covering certain forms of COVID-19 testing.The crisis necessitated shutdowns of restaurants, office buildings, gyms, sports and entertainment venues and other businesses. Unemployment in the U.S. rose sharply from 3.5% in January 2020 to 14.7% in April, and more than 20 million people lost their jobs in April alone. 

# 1. Data Selection and Integration
Data Sources:
1.	https://www.worldometers.info/coronavirus/countries-where-coronavirus-has-spread/
2.	https://covidtracking.com/data/api
1.We have 2 different data source. First dataset comes from Worldmeter(Real time world statics) .There are 4 columns and 1000 records.This date is up to date , so recors depends on the date.The dataset has predictor 'Country',"Cases","Deaths","Recovered".
2.Second Dataset is USA official government web site, the most affected country in the world. Records are officially source means public. I used the dataset to create a series of interactive Tableau dashboards exploring which states are experiencing the most severe economic fallout from COVID-19, and how that tracks with the states hit hardest by the virus itself. There are 4 columns and 2500 records.	

![image](https://github.com/emrah-uzdilli/Covid-19-and-Unemployment-Data-Analysis/assets/62702253/2c3fba76-db5a-4bb4-9b38-ae79ac3b4c7a)

# 2. Data-Cleaning and pre-processing
Data reliability is very important for data driven decision making. Data cleaning includes removing unwanted characters, handling missing values and outliers, etc.
In our search, unwanted columns like ‘Region’ were removed from the dataset. Hence data manipulation was done these columns to bring the data into required format.
Also, With the filtering method, we can manipulate the data we want more easily.

![image](https://github.com/emrah-uzdilli/Covid-19-and-Unemployment-Data-Analysis/assets/62702253/98089e41-1c44-4aca-a6f2-9c383ce6a18d)

# Virtualization
Data virtualization software acts as a bridge across multiple, diverse data sources, bringing critical decision-making data together in one virtual place to fuel analytics.

![pltunemployment](https://github.com/emrah-uzdilli/Covid-19-and-Unemployment-Data-Analysis/assets/62702253/da3596e1-554f-4fd6-b2c5-c539327633b1)
![plt3data](https://github.com/emrah-uzdilli/Covid-19-and-Unemployment-Data-Analysis/assets/62702253/494d126b-b2df-4f57-a6eb-930b143ef6ba)
